TODO should the parser and lexer provide their own Accept, Reject and Reason types?
DONE Rename 'Any' to 'Anything'
DONE update README.md
DONE cleanup imports
DONE cleanup repositories

[ Matchers ]
    DONE implement a Rejection Reason

[ Lexer ]
    TODO return a result accepting or rejecting the tokenized string, consider cases:
        Unexpected tokens
        No remaining tokens
        Trailing tokens
    TODO matching is done for every rule, for every token, it could probably be done more efficiently with a DFA
    DONE support pre-made matchers
        DONE whitespaces
        DONE newlines
        DONE "AnyOperator" should be renamed to something less misleading
        DONE change "any" to "anything"
    DONE test rule order
    DONE bug: lexer is not taking the longest match
    DONE add a reference to the corresponding line text to each token
    DONE add start and end indices to Token
    DONE proper error output
    DONE implement line and column numbers
    DONE refactor ignore and produce rules in lexer
    DONE write a simple playbook

[ Parser ]
    TODO bad parenthesis break everything on the parser
    DONE add TerminalByContent to dsl as terminal(Token("..."))
    DONE proper error output
    DONE consider premature EOF
    DONE always consume all input
    DONE match terminal symbols
    DONE write a simple playbook
